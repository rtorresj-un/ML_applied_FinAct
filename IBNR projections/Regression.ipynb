{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression models for IBNR estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After estimating IBNR using traditional methods, we're going to model run-off triangles data with some additional methods, in order to accomplish main project's objective. \n",
    "\n",
    "The models that are presented next are a traditional linear regression, ridge regression and lasso regression, taking as input a variables `X` and `Y` for every company in the reequired timespan.\n",
    "\n",
    "## Model construction\n",
    "\n",
    "This method is based on Kremer's(1982) approach exposed on Verrall(1985). Under lognormal and identically distributed assumptions (and every other that applies to a regression model) the chainladder procedure based on multiplicative display could be described as the following equation: \n",
    "\n",
    "$$E(Z_{i,j})=U_iS_j$$\n",
    "\n",
    "Where $U_i$ is a parameter for row i and $S_j$ is a parameter for column j. Then, if $Y_{i,j} = \\operatorname{ln}(Z_{i,j})$ and if $U_i = e^{\\alpha_i+\\mu}\\sum^t_{j=1}e^{\\beta_j}$, we have the equation \n",
    "\n",
    "$$y=X\\Beta + \\varepsilon$$\n",
    "\n",
    "Where $X$ is a non-singular design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnas(valores,variable):\n",
    "    y = [re.findall(\"\\\\d+\", j)[0] for j in valores]\n",
    "    y = [int(i) for i in y]\n",
    "    todas = list(set(y))\n",
    "    df = pd.DataFrame()\n",
    "    df[f\"y_{variable}\"] = y\n",
    "    for k in todas:\n",
    "        #print(k)\n",
    "        df[f\"{variable}_{k}\"] = ([1 if k == j else 0 for j in y])\n",
    "    return df\n",
    "\n",
    "def matrix_X(df_triangulo):\n",
    "    k = len(df_triangulo.columns)\n",
    "    alpha = [f'a_{i}' for i in range(1,k+1)]\n",
    "    mu    = [f'u_{i}' for i in range(1,k+1)]\n",
    "    lists = [alpha, mu]\n",
    "    df    = pd.DataFrame(list(itertools.product(*lists)), columns=['a', 'u'])\n",
    "\n",
    "    alpha    = columnas(valores  = df.a, variable = 'a')\n",
    "    mu       = columnas(valores=df.u, variable = 'u')\n",
    "    df_col= pd.concat([alpha, mu], axis=1)\n",
    "\n",
    "\n",
    "    df_col['y_a'] = df_col['y_a'].astype(str) + df_col['y_u'].astype(str) \n",
    "    df_col['y_a'] = [int(i) for i in df_col['y_a']]\n",
    "    df_col = df_col.drop(['y_u', 'u_1'], axis=1)\n",
    "    df_col['a_1'] = 1\n",
    "    df_col.rename(columns={'a_1': 'b0'}, inplace=True)\n",
    "    df_col.rename(columns={'y_a': 'y_ii'}, inplace=True)\n",
    "    #df_col = df_col.drop(['y_ii'], axis=1)\n",
    "    return df_col\n",
    "\n",
    "def matrix_y(df_triangulo):\n",
    "    k = len(df_triangulo.columns)\n",
    "    d0 = pd.DataFrame()\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            d1 = pd.DataFrame({'y_ii': [int(f'{i+1}{j+1}')], 'Y': [math.log(df_triangulo.iloc[i, j])]})\n",
    "            d0 = pd.concat([d0, d1], axis=0)\n",
    "    return d0\n",
    "\n",
    "def triangulo(df, grcode, entreno):\n",
    "    \n",
    "    if entreno:\n",
    "        df_trinagulo = df[(df['GRCODE']== grcode ) & (df['DevelopmentYear']<=1997)].copy()\n",
    "    else: \n",
    "        df_trinagulo = df[df['GRCODE']== grcode].copy()\n",
    "        \n",
    "    df_g         = df_trinagulo.groupby([\"AccidentYear\", \"DevelopmentLag\"]).agg({'IncurLoss_B': ['max']})\n",
    "    df_g.columns = ['Pagos']\n",
    "    df_g         = df_g.reset_index()\n",
    "    pivot_data   = df_g.pivot(index='AccidentYear',columns='DevelopmentLag',values='Pagos').reset_index()\n",
    "    pivot_data   = pivot_data.drop('AccidentYear', axis=1).cumsum(axis=1)\n",
    "    \n",
    "    return pivot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.read_csv(os.path.normpath(os.getcwd() + os.sep + os.pardir)+\"/data/ppauto_pos.csv\")\n",
    "\n",
    "input = input[input.DevelopmentYear <= 1997]\n",
    "\n",
    "cleaning_cond = np.array(['Adriatic Ins Co', 'Aegis Grp', 'Agency Ins Co Of MD Inc',\n",
    "       'Allegheny Cas Co', 'American Modern Ins Grp Inc',\n",
    "       'Armed Forces Ins Exchange', 'Auto Club South Ins Co',\n",
    "       'Baltica-Skandinavia Rein Co Of Amer', 'Bancinsure Inc',\n",
    "       'Bell United Ins Co', 'Century-Natl Ins Co', 'Co-Operative Ins Co',\n",
    "       'Consumers Ins Usa Inc', 'Cornerstone Natl Ins Co',\n",
    "       'Federated Natl Ins Co', 'First Amer Ins Co',\n",
    "       'Florists Mut Ins Grp', 'Harbor Ins Co', 'Homestead Ins Co',\n",
    "       'Inland Mut Ins Co', 'Interstate Auto Ins Co Inc', 'Lancer Ins Co',\n",
    "       'Lumber Ins Cos', 'Manhattan Re Ins Co', 'Mennonite Mut Ins Co',\n",
    "       'Middle States Ins Co Inc', 'National Automotive Ins',\n",
    "       'Nevada General Ins Co', 'New Jersey Citizens United Rcp Exch',\n",
    "       'Nichido Fire & Marine Ins Co Ltd', 'Northwest Gf Mut Ins Co',\n",
    "       'Ocean Harbor Cas Ins Co', 'Overseas Partners Us Reins Co',\n",
    "       'Pacific Ind Ins Co', 'Pacific Pioneer Ins Co',\n",
    "       'Pacific Specialty Ins Co', 'Penn Miller Grp',\n",
    "       'Pennsylvania Mfg Asn Ins Co', 'Pioneer State Mut Ins Co',\n",
    "       'Protective Ins Grp', 'San Antonio Reins Co',\n",
    "       'Seminole Cas Ins Co', 'Southern Group Ind Inc',\n",
    "       'Southern Mut Ins Co', 'Southland Lloyds Ins Co', 'Star Ins Grp',\n",
    "       'Sterling Ins Co', 'Usauto Ins Co', 'Vanliner Ins Co',\n",
    "       'Wea Prop & Cas Ins Co', 'Wellington Ins Co', 'State Farm Mut Grp', 'United Services Automobile Asn Grp',\n",
    "       'US Lloyds Ins Co', 'Toa-Re Ins Co Of Amer', 'FL Farm Bureau Grp'])\n",
    "\n",
    "input = input[~input.GRNAME.isin(cleaning_cond)]\n",
    "\n",
    "Lista_entidades_ceros = input[input.IncurLoss_B <= 0][\"GRCODE\"].unique()\n",
    "input = input[~input.GRCODE.isin(Lista_entidades_ceros)]\n",
    "#input.IncurLoss_B = input.IncurLoss_B+1 #deal with NaN from log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>DevelopmentLag</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>607.0</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>2434.0</td>\n",
       "      <td>3048.0</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>4892.0</td>\n",
       "      <td>5506.0</td>\n",
       "      <td>6120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2254.0</td>\n",
       "      <td>5113.0</td>\n",
       "      <td>8092.0</td>\n",
       "      <td>10856.0</td>\n",
       "      <td>13682.0</td>\n",
       "      <td>16699.0</td>\n",
       "      <td>19689.0</td>\n",
       "      <td>22667.0</td>\n",
       "      <td>25645.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5843.0</td>\n",
       "      <td>13267.0</td>\n",
       "      <td>21574.0</td>\n",
       "      <td>30245.0</td>\n",
       "      <td>39311.0</td>\n",
       "      <td>48237.0</td>\n",
       "      <td>57004.0</td>\n",
       "      <td>65769.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11422.0</td>\n",
       "      <td>27515.0</td>\n",
       "      <td>46163.0</td>\n",
       "      <td>65258.0</td>\n",
       "      <td>83911.0</td>\n",
       "      <td>102380.0</td>\n",
       "      <td>120787.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19933.0</td>\n",
       "      <td>44095.0</td>\n",
       "      <td>72834.0</td>\n",
       "      <td>101163.0</td>\n",
       "      <td>129234.0</td>\n",
       "      <td>156956.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24604.0</td>\n",
       "      <td>56734.0</td>\n",
       "      <td>90309.0</td>\n",
       "      <td>123078.0</td>\n",
       "      <td>156800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40735.0</td>\n",
       "      <td>84679.0</td>\n",
       "      <td>127190.0</td>\n",
       "      <td>168902.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43064.0</td>\n",
       "      <td>86769.0</td>\n",
       "      <td>129678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41837.0</td>\n",
       "      <td>83141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44436.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "DevelopmentLag       1        2         3         4         5         6   \\\n",
       "0                 607.0   1254.0    1836.0    2434.0    3048.0    3663.0   \n",
       "1                2254.0   5113.0    8092.0   10856.0   13682.0   16699.0   \n",
       "2                5843.0  13267.0   21574.0   30245.0   39311.0   48237.0   \n",
       "3               11422.0  27515.0   46163.0   65258.0   83911.0  102380.0   \n",
       "4               19933.0  44095.0   72834.0  101163.0  129234.0  156956.0   \n",
       "5               24604.0  56734.0   90309.0  123078.0  156800.0       NaN   \n",
       "6               40735.0  84679.0  127190.0  168902.0       NaN       NaN   \n",
       "7               43064.0  86769.0  129678.0       NaN       NaN       NaN   \n",
       "8               41837.0  83141.0       NaN       NaN       NaN       NaN   \n",
       "9               44436.0      NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "DevelopmentLag        7        8        9       10  \n",
       "0                 4278.0   4892.0   5506.0  6120.0  \n",
       "1                19689.0  22667.0  25645.0     NaN  \n",
       "2                57004.0  65769.0      NaN     NaN  \n",
       "3               120787.0      NaN      NaN     NaN  \n",
       "4                    NaN      NaN      NaN     NaN  \n",
       "5                    NaN      NaN      NaN     NaN  \n",
       "6                    NaN      NaN      NaN     NaN  \n",
       "7                    NaN      NaN      NaN     NaN  \n",
       "8                    NaN      NaN      NaN     NaN  \n",
       "9                    NaN      NaN      NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data        = input #pd.read_csv('medmal_pos.csv')\n",
    "df_trg_entreno = triangulo(df_data, grcode=43, entreno=True)\n",
    "df_trg_prueba  = triangulo(df_data, grcode=43, entreno=False)\n",
    "df_trg_entreno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>b0</th>\n",
       "      <th>a_2</th>\n",
       "      <th>a_3</th>\n",
       "      <th>a_4</th>\n",
       "      <th>a_5</th>\n",
       "      <th>a_6</th>\n",
       "      <th>a_7</th>\n",
       "      <th>a_8</th>\n",
       "      <th>a_9</th>\n",
       "      <th>a_10</th>\n",
       "      <th>u_2</th>\n",
       "      <th>u_3</th>\n",
       "      <th>u_4</th>\n",
       "      <th>u_5</th>\n",
       "      <th>u_6</th>\n",
       "      <th>u_7</th>\n",
       "      <th>u_8</th>\n",
       "      <th>u_9</th>\n",
       "      <th>u_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.408529</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.134094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.515345</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.797291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.022241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Y  b0  a_2  a_3  a_4  a_5  a_6  a_7  a_8  a_9  a_10  u_2  u_3  u_4  \\\n",
       "0  6.408529   1    0    0    0    0    0    0    0    0     0    0    0    0   \n",
       "1  7.134094   1    0    0    0    0    0    0    0    0     0    1    0    0   \n",
       "2  7.515345   1    0    0    0    0    0    0    0    0     0    0    1    0   \n",
       "3  7.797291   1    0    0    0    0    0    0    0    0     0    0    0    1   \n",
       "4  8.022241   1    0    0    0    0    0    0    0    0     0    0    0    0   \n",
       "\n",
       "   u_5  u_6  u_7  u_8  u_9  u_10  \n",
       "0    0    0    0    0    0     0  \n",
       "1    0    0    0    0    0     0  \n",
       "2    0    0    0    0    0     0  \n",
       "3    0    0    0    0    0     0  \n",
       "4    1    0    0    0    0     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = matrix_y(df_trg_entreno)\n",
    "X = matrix_X(df_trg_entreno)\n",
    "\n",
    "Y_X          = pd.merge(Y, X, on='y_ii', how='inner')\n",
    "data_entreno = Y_X[Y_X['Y'].notna()]\n",
    "data_entreno = data_entreno.drop(['y_ii'], axis=1)\n",
    "data_entreno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prueba      = matrix_y(df_trg_prueba)                   \n",
    "x_prueba      = Y_X[Y_X['Y'].notna()].drop(['Y'], axis=1)\n",
    "data_prueba_  = pd.merge(Y_prueba, x_prueba, on='y_ii', how='inner')\n",
    "data_prueba=data_prueba_.drop(['y_ii'], axis=1)\n",
    "y_ii = data_prueba_['y_ii']\n",
    "\n",
    "x_entreno = data_entreno.drop('Y', axis=1)  # Features\n",
    "y_entreno = data_entreno['Y']  # Target variable\n",
    "x_prueba  = data_prueba.drop('Y', axis=1)  # Features\n",
    "y_prueba  = data_prueba['Y']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models considered:\n",
    "\n",
    "The next steps require estimating three type of models:\n",
    "\n",
    "### Ordinary Least Squares regression\n",
    "\n",
    "The simple linear regression consists of generating a regression model (equation of a line) that explains the linear relationship between two variables. The dependent or response variable is identified as $Y$, and the predictor or independent variable is identified as $X$.\n",
    "\n",
    "The simple linear regression model is described according to the equation:\n",
    "$$Y =\\beta_{0} + \\beta_{1}X_{1}+\\varepsilon$$\n",
    "\n",
    "Here, $\\beta_0$ is the y-intercept, $\\beta_1$ is the slope, and $\\varepsilon is the random error. The random error represents the difference between the value adjusted by the line and the actual value. It captures the effect of all those variables that influence $Y$ but are not included in the model as predictors. The random error is also known as the residual.\n",
    "\n",
    "In the vast majority of cases, the population values of $\\beta_0$ and \\beta_1$ are unknown. Therefore, from a sample, their estimations are obtained, these estimates are known as regression coefficients or least square coefficient estimates since they take values that minimize the sum of squared residuals, resulting in the line that passes closest to all points.\n",
    "\n",
    "### Ridge regression\n",
    "\n",
    "Ridge regularization penalizes the sum of the coefficients squared. This penalty has the effect of proportionally reducing the value of all coefficients in the model without letting them reach zero. The degree of penalization is controlled by the hyperparameter $\\lambda$. When $\\lambda=0$, the penalty is null, and the result is equivalent to that of a linear model by ordinary least squares (OLS). As λ increases, the penalty becomes stronger, and the values of the predictors decrease.\n",
    "\n",
    "\n",
    "$$\\sum^n_{i=1}(y_i - \\beta_0 - \\sum^p_{j=1} \\beta_j x_{ij})^2 + \\lambda \\sum^p_{j=1} \\beta_j^2 = \\text{residual squared sum} + \\lambda \\sum^p_{j=1} \\beta_j^2$$\n",
    "\n",
    "The main advantage of applying ridge over ordinary least squares (OLS) fitting is the reduction of variance. Generally, in situations where the relationship between the response variable and predictors is approximately linear, least squares estimates have little bias but can still suffer from high variance (small changes in the training data have a significant impact on the resulting model). This problem is accentuated as the number of predictors introduced into the model approaches the number of training observations, reaching the point where, if $p>n$, it is not possible to fit the model by ordinary least squares. By using an appropriate value of λ, the ridge method can reduce variance without significantly increasing bias, thus achieving lower total error.\n",
    "\n",
    "The disadvantage of the ridge method is that the final model includes all predictors. This is because, although the penalty forces the coefficients to tend toward zero, they never become exactly zero (only if $\\lambda=\\inf$). This method minimizes the influence on the model of predictors less related to the response variable, but in the final model, they will still appear. Although this is not a problem for the accuracy of the model, it is a challenge for its interpretation\n",
    "\n",
    "### Lasso regression\n",
    "\n",
    "Lasso regularization penalizes the sum of the absolute values of the regression coefficients. This penalty is known as l1 and has the effect of forcing the coefficients of the predictors to tend towards zero. Since a predictor with a regression coefficient of zero does not influence the model, lasso manages to exclude the less relevant predictors. Similar to ridge, the degree of penalization is controlled by the hyperparameter λ. When λ = 0, the result is equivalent to that of a linear model by ordinary least squares. As λ increases, the penalty becomes stronger, and more predictors are excluded.\n",
    "\n",
    "$$\\sum^n_{i=1}(y_i - \\beta_0 - \\sum^p_{j=1} \\beta_j x_{ij})^2 + \\lambda \\sum^p_{j=1} |\\beta_j| = \\text{residual squared sum} + \\lambda \\sum^p_{j=1} |\\beta_j|$$\n",
    "\n",
    "The main practical difference between lasso and ridge is that the former manages to make some coefficients exactly zero, thus performing predictor selection, while the latter does not exclude any. This represents a significant advantage of lasso in scenarios where not all predictors are important for the model, and it is desired that the least influential ones be excluded.\n",
    "\n",
    "On the other hand, when there are highly correlated predictors (linearly), ridge reduces the influence of all of them simultaneously and proportionally, while lasso tends to select one of them, giving it all the weight and excluding the others. In the presence of correlations, this selection varies a lot with small perturbations (changes in the training data), so lasso solutions are very unstable if predictors are highly correlated, which is taken into account in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002230701729399499, 0.0038343781268415497]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Regresion_lineal = LinearRegression()\n",
    "Regresion_lineal.fit(x_entreno, y_entreno)\n",
    "LR_coef = Regresion_lineal.coef_\n",
    "y_pred = Regresion_lineal.predict(x_prueba)\n",
    "\n",
    "mse = mean_squared_error(y_prueba, y_pred)   # Considerar que se debe aplicar la exponencial a los rsultados\n",
    "mape = mean_absolute_percentage_error(y_prueba, y_pred)   # COnsiderar que se debe aplicar la exponencial a los rsultados\n",
    "[mse, mape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002230702303162153, 0.003834869524506071]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.00001\n",
    "ridge_model = Ridge(alpha = alpha) #aplicación regresión de ridge\n",
    "ridge_model.fit(x_entreno, y_entreno) #entrenamiento regresión de ridge\n",
    "ridge_coef = ridge_model.coef_ #coeficientes regresión de ridge\n",
    "y_pred = ridge_model.predict(x_prueba)\n",
    "\n",
    "mse = mean_squared_error(y_prueba, y_pred)   # COnsiderar que se debe aplicar la exponencial a los rsultados\n",
    "mape = mean_absolute_percentage_error(y_prueba, y_pred)   # COnsiderar que se debe aplicar la exponencial a los rsultados\n",
    "[mse, mape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0022309333284786215, 0.0038438188771605904]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha = alpha) #aplicación regresión de lasso\n",
    "lasso_model.fit(x_entreno, y_entreno) #entrenamiento regresión de lasso\n",
    "lasso_coef = lasso_model.coef_ #coeficientes regresión de lasso\n",
    "y_pred = lasso_model.predict(x_prueba)\n",
    "\n",
    "mse = mean_squared_error(y_prueba, y_pred)   # Considerar que se debe aplicar la exponencial a los rsultados\n",
    "mape = mean_absolute_percentage_error(y_prueba, y_pred)   # Considerar que se debe aplicar la exponencial a los rsultados\n",
    "[mse, mape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   523.69588732,   1138.91125798,   1800.60267558,   2481.25822179,\n",
       "         3197.47927039,   3891.61694156,   4565.05488313,   5164.35159533,\n",
       "         5680.89885172,   6130.        ,   2295.86135051,   4992.94037277,\n",
       "         7893.76848391,  10877.73455923,  14017.61834235,  17060.68950208,\n",
       "        20013.01389388,  22640.30616852,  24904.82821343,   6338.44464237,\n",
       "        13784.57638498,  21793.22133009,  30031.39467575,  38700.02770899,\n",
       "        47101.37916013,  55252.19572384,  62505.6592827 ,  13208.63690653,\n",
       "        28725.57459323,  45414.72929312,  62582.19649294,  80646.69538382,\n",
       "        98154.20820492, 115139.6332668 ,  20832.59948126,  45305.8400049 ,\n",
       "        71627.89564198,  98704.34348534, 127195.58545728, 154808.35164171,\n",
       "        25717.11423791,  55928.47230123,  88422.12785315, 121847.05415536,\n",
       "       157018.49424527,  38030.54940143,  82707.20070384, 130758.92070899,\n",
       "       180187.806828  ,  40167.54770632,  87354.65256788, 138106.47672126,\n",
       "        39993.8249981 ,  86976.84790502,  44437.        ])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "Next to model implementation and checking on the similar results of the three modeling procedures, we need to train, validate and test to find the best model of IBNR. Thus, we proceed next with a Cross Validation, running on a list of 10 insurers and excluding one at a time on a loop that splits every insurer's sub-sample on training, validation and testing data.\n",
    "\n",
    "With this in mind, the next loop estimate the three models for every company. The process is completed once every company has already trained, validated and tested each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aseguradora de test: 0\n",
      "aseguradora de test: 1\n",
      "aseguradora de test: 2\n",
      "aseguradora de test: 3\n",
      "aseguradora de test: 4\n",
      "aseguradora de test: 5\n",
      "aseguradora de test: 6\n",
      "aseguradora de test: 7\n",
      "aseguradora de test: 8\n",
      "aseguradora de test: 9\n"
     ]
    }
   ],
   "source": [
    "df_CV = input[input[\"GRCODE\"].isin(list(input[\"GRCODE\"].unique()[0:10]))]\n",
    "lista_aseguradoras = df_CV[\"GRCODE\"].unique()\n",
    "mejore_modelos_test_full = {}\n",
    "mejores_mape = {}\n",
    "\n",
    "for i in range(len(lista_aseguradoras)): #recorre las aseguradoras de test\n",
    "    print(\"aseguradora de test:\", i)\n",
    "    conj_test = lista_aseguradoras[i] #codigo de aseguradora de testeo\n",
    "    datos_test = df_CV[df_CV[\"GRCODE\"].isin([conj_test])] #datos de aseguradora de testeo\n",
    "    conj_entre_valid = np.delete(lista_aseguradoras, i, axis=0) #Conjunto de validación y entrenamiento\n",
    "\n",
    "    for j in range(len(conj_entre_valid)): #recorre los datos de entrenamiento y validación\n",
    "\n",
    "        conj_vali = conj_entre_valid[j] #datos de aseguradora de validación\n",
    "        conj_entre = np.delete(conj_entre_valid, j, axis=0) #aseguradoras de entrenamiento\n",
    "        datos_train = df_CV[df_CV[\"GRCODE\"].isin(conj_entre)] #datos de aseguradoras de entrenamiento\n",
    "        datos_validacion = df_CV[df_CV[\"GRCODE\"].isin([conj_vali])] #datos de aseguradora de validación\n",
    "\n",
    "        #Se crea la clase que calculará las regresiones\n",
    "        df_data        = input #pd.read_csv('medmal_pos.csv')\n",
    "        df_trg_entreno = triangulo(datos_train, entreno=True, grcode=43)\n",
    "        df_trg_prueba  = triangulo(datos_validacion, entreno=False, grcode=conj_vali)\n",
    "\n",
    "        Y_prueba      = matrix_y(df_trg_prueba)                   \n",
    "        x_prueba      = Y_X[Y_X['Y'].notna()].drop(['Y'], axis=1)\n",
    "        data_prueba_  = pd.merge(Y_prueba, x_prueba, on='y_ii', how='inner')\n",
    "        data_prueba=data_prueba_.drop(['y_ii'], axis=1)\n",
    "        y_ii = data_prueba_['y_ii']\n",
    "\n",
    "        x_entreno = data_entreno.drop('Y', axis=1)  # Features\n",
    "        y_entreno = data_entreno['Y']  # Target variable\n",
    "        x_prueba  = data_prueba.drop('Y', axis=1)  # Features\n",
    "        y_prueba  = data_prueba['Y']  # Target variable\n",
    "\n",
    "        Regresion_lineal.fit(x_entreno, y_entreno)\n",
    "        LR_coef = Regresion_lineal.coef_\n",
    "        y_pred_1 = Regresion_lineal.predict(x_prueba)\n",
    "        mape_1 = mean_squared_error(y_prueba, y_pred_1)\n",
    "        Regresion_lineal_sum = [Regresion_lineal.intercept_, Regresion_lineal.coef_, Regresion_lineal.score(x_prueba, y_prueba)]\n",
    "\n",
    "        ridge_model.fit(x_entreno, y_entreno)\n",
    "        ridge_coef = Regresion_lineal.coef_\n",
    "        y_pred_2 = ridge_model.predict(x_prueba)\n",
    "        mape_2 = mean_squared_error(y_prueba, y_pred_2)\n",
    "        ridge_sum = [ridge_model.intercept_, ridge_model.coef_, ridge_model.score(x_prueba, y_prueba)]\n",
    "\n",
    "        lasso_model.fit(x_entreno, y_entreno)\n",
    "        lasso_coef = Regresion_lineal.coef_\n",
    "        y_pred_3 = lasso_model.predict(x_prueba)\n",
    "        mape_3 = mean_squared_error(y_prueba, y_pred_3)\n",
    "        lasso_sum = [lasso_model.intercept_, lasso_model.coef_, lasso_model.score(x_prueba, y_prueba)]\n",
    "\n",
    "        results = [mape_1, mape_2, mape_3]\n",
    "        models = [Regresion_lineal_sum, ridge_sum, lasso_sum]\n",
    "\n",
    "        if (mape_1<mape_2) & (mape_1<mape_3):\n",
    "            modelo_test=Regresion_lineal\n",
    "            if (mape_2<mape_1) & (mape_2<mape_3):\n",
    "                modelo_test=ridge_model\n",
    "            else:\n",
    "                modelo_test=lasso_model\n",
    "                    \n",
    "        y_pred = modelo_test.predict(x_prueba)\n",
    "        mejores_mape[i,j] = mean_squared_error(y_prueba, y_pred)\n",
    "\n",
    "        mejore_modelos_test_full[\"modelo_\"+str(i)+\"-\"+str(j)] = modelo_test #se guardan los mejores modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict(sorted(mejores_mape.items(), key=lambda item: item[1])).keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modelo_0-0': Lasso(alpha=1e-05),\n",
       " 'modelo_0-1': Lasso(alpha=1e-05),\n",
       " 'modelo_0-2': Lasso(alpha=1e-05),\n",
       " 'modelo_0-3': Lasso(alpha=1e-05),\n",
       " 'modelo_0-4': Lasso(alpha=1e-05),\n",
       " 'modelo_0-5': Lasso(alpha=1e-05),\n",
       " 'modelo_0-6': Lasso(alpha=1e-05),\n",
       " 'modelo_0-7': Lasso(alpha=1e-05),\n",
       " 'modelo_0-8': Lasso(alpha=1e-05),\n",
       " 'modelo_1-0': Lasso(alpha=1e-05),\n",
       " 'modelo_1-1': Lasso(alpha=1e-05),\n",
       " 'modelo_1-2': Lasso(alpha=1e-05),\n",
       " 'modelo_1-3': Lasso(alpha=1e-05),\n",
       " 'modelo_1-4': Lasso(alpha=1e-05),\n",
       " 'modelo_1-5': Lasso(alpha=1e-05),\n",
       " 'modelo_1-6': Lasso(alpha=1e-05),\n",
       " 'modelo_1-7': Lasso(alpha=1e-05),\n",
       " 'modelo_1-8': Lasso(alpha=1e-05),\n",
       " 'modelo_2-0': Lasso(alpha=1e-05),\n",
       " 'modelo_2-1': Lasso(alpha=1e-05),\n",
       " 'modelo_2-2': Lasso(alpha=1e-05),\n",
       " 'modelo_2-3': Lasso(alpha=1e-05),\n",
       " 'modelo_2-4': Lasso(alpha=1e-05),\n",
       " 'modelo_2-5': Lasso(alpha=1e-05),\n",
       " 'modelo_2-6': Lasso(alpha=1e-05),\n",
       " 'modelo_2-7': Lasso(alpha=1e-05),\n",
       " 'modelo_2-8': Lasso(alpha=1e-05),\n",
       " 'modelo_3-0': Lasso(alpha=1e-05),\n",
       " 'modelo_3-1': Lasso(alpha=1e-05),\n",
       " 'modelo_3-2': Lasso(alpha=1e-05),\n",
       " 'modelo_3-3': Lasso(alpha=1e-05),\n",
       " 'modelo_3-4': Lasso(alpha=1e-05),\n",
       " 'modelo_3-5': Lasso(alpha=1e-05),\n",
       " 'modelo_3-6': Lasso(alpha=1e-05),\n",
       " 'modelo_3-7': Lasso(alpha=1e-05),\n",
       " 'modelo_3-8': Lasso(alpha=1e-05),\n",
       " 'modelo_4-0': Lasso(alpha=1e-05),\n",
       " 'modelo_4-1': Lasso(alpha=1e-05),\n",
       " 'modelo_4-2': Lasso(alpha=1e-05),\n",
       " 'modelo_4-3': Lasso(alpha=1e-05),\n",
       " 'modelo_4-4': Lasso(alpha=1e-05),\n",
       " 'modelo_4-5': Lasso(alpha=1e-05),\n",
       " 'modelo_4-6': Lasso(alpha=1e-05),\n",
       " 'modelo_4-7': Lasso(alpha=1e-05),\n",
       " 'modelo_4-8': Lasso(alpha=1e-05),\n",
       " 'modelo_5-0': Lasso(alpha=1e-05),\n",
       " 'modelo_5-1': Lasso(alpha=1e-05),\n",
       " 'modelo_5-2': Lasso(alpha=1e-05),\n",
       " 'modelo_5-3': Lasso(alpha=1e-05),\n",
       " 'modelo_5-4': Lasso(alpha=1e-05),\n",
       " 'modelo_5-5': Lasso(alpha=1e-05),\n",
       " 'modelo_5-6': Lasso(alpha=1e-05),\n",
       " 'modelo_5-7': Lasso(alpha=1e-05),\n",
       " 'modelo_5-8': Lasso(alpha=1e-05),\n",
       " 'modelo_6-0': Lasso(alpha=1e-05),\n",
       " 'modelo_6-1': Lasso(alpha=1e-05),\n",
       " 'modelo_6-2': Lasso(alpha=1e-05),\n",
       " 'modelo_6-3': Lasso(alpha=1e-05),\n",
       " 'modelo_6-4': Lasso(alpha=1e-05),\n",
       " 'modelo_6-5': Lasso(alpha=1e-05),\n",
       " 'modelo_6-6': Lasso(alpha=1e-05),\n",
       " 'modelo_6-7': Lasso(alpha=1e-05),\n",
       " 'modelo_6-8': Lasso(alpha=1e-05),\n",
       " 'modelo_7-0': Lasso(alpha=1e-05),\n",
       " 'modelo_7-1': Lasso(alpha=1e-05),\n",
       " 'modelo_7-2': Lasso(alpha=1e-05),\n",
       " 'modelo_7-3': Lasso(alpha=1e-05),\n",
       " 'modelo_7-4': Lasso(alpha=1e-05),\n",
       " 'modelo_7-5': Lasso(alpha=1e-05),\n",
       " 'modelo_7-6': Lasso(alpha=1e-05),\n",
       " 'modelo_7-7': Lasso(alpha=1e-05),\n",
       " 'modelo_7-8': Lasso(alpha=1e-05),\n",
       " 'modelo_8-0': Lasso(alpha=1e-05),\n",
       " 'modelo_8-1': Lasso(alpha=1e-05),\n",
       " 'modelo_8-2': Lasso(alpha=1e-05),\n",
       " 'modelo_8-3': Lasso(alpha=1e-05),\n",
       " 'modelo_8-4': Lasso(alpha=1e-05),\n",
       " 'modelo_8-5': Lasso(alpha=1e-05),\n",
       " 'modelo_8-6': Lasso(alpha=1e-05),\n",
       " 'modelo_8-7': Lasso(alpha=1e-05),\n",
       " 'modelo_8-8': Lasso(alpha=1e-05),\n",
       " 'modelo_9-0': Lasso(alpha=1e-05),\n",
       " 'modelo_9-1': Lasso(alpha=1e-05),\n",
       " 'modelo_9-2': Lasso(alpha=1e-05),\n",
       " 'modelo_9-3': Lasso(alpha=1e-05),\n",
       " 'modelo_9-4': Lasso(alpha=1e-05),\n",
       " 'modelo_9-5': Lasso(alpha=1e-05),\n",
       " 'modelo_9-6': Lasso(alpha=1e-05),\n",
       " 'modelo_9-7': Lasso(alpha=1e-05),\n",
       " 'modelo_9-8': Lasso(alpha=1e-05)}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejore_modelos_test_full #winner is number 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = mejore_modelos_test_full['modelo_1-0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see, the best model is a Lasso regression with the next parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.47844251, 2.49413039, 3.22837566, 3.68398512,\n",
       "       3.89455874, 4.28571065, 4.34024567, 4.33566825, 4.44036036,\n",
       "       0.77618137, 1.23415607, 1.5547379 , 1.80827364, 2.00466563,\n",
       "       2.16418097, 2.28739579, 2.38248208, 2.45789794])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data        = input\n",
    "df_trg_prueba  = triangulo(df_data, grcode=43, entreno=False)\n",
    "\n",
    "Y_prueba      = matrix_y(df_trg_prueba)                   \n",
    "x_prueba      = Y_X[Y_X['Y'].notna()].drop(['Y'], axis=1)\n",
    "data_prueba_  = pd.merge(Y_prueba, x_prueba, on='y_ii', how='inner')\n",
    "data_prueba=data_prueba_.drop(['y_ii'], axis=1)\n",
    "y_ii = data_prueba_['y_ii']\n",
    "\n",
    "X_test  = data_prueba.drop('Y', axis=1)  # Features\n",
    "Y_test  = data_prueba['Y']  # Target variable\n",
    "\n",
    "\n",
    "Y_pred = winner.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we recall that this model offers us a MAPE of 0.002, according to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0022309333284786215"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_mape[(1,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the predictions, we must see that the error values are short in comparison with the other models implemented. Next to this, the model's prediction are computed in terms of \\$USD. Thus, model predicts that IBNR's for the largest development year must be \\$USD 180,109.086, compared to actual IBNR's of \\$USD 168,902 the difference is 0.53\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Percentage difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>607.0</td>\n",
       "      <td>523.674041</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1254.0</td>\n",
       "      <td>1138.026387</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1836.0</td>\n",
       "      <td>1799.070652</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2434.0</td>\n",
       "      <td>2478.992060</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3048.0</td>\n",
       "      <td>3194.363303</td>\n",
       "      <td>-0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3663.0</td>\n",
       "      <td>3887.552493</td>\n",
       "      <td>-0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4278.0</td>\n",
       "      <td>4559.874610</td>\n",
       "      <td>-0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4892.0</td>\n",
       "      <td>5157.798995</td>\n",
       "      <td>-0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5506.0</td>\n",
       "      <td>5672.308827</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6120.0</td>\n",
       "      <td>6116.634925</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2254.0</td>\n",
       "      <td>2296.891439</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5113.0</td>\n",
       "      <td>4991.507813</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8092.0</td>\n",
       "      <td>7890.920032</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10856.0</td>\n",
       "      <td>10873.129458</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13682.0</td>\n",
       "      <td>14010.825728</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16699.0</td>\n",
       "      <td>17051.229096</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19689.0</td>\n",
       "      <td>20000.107205</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22667.0</td>\n",
       "      <td>22622.668748</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25645.0</td>\n",
       "      <td>24879.364967</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5843.0</td>\n",
       "      <td>6342.319410</td>\n",
       "      <td>-0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13267.0</td>\n",
       "      <td>13782.861632</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21574.0</td>\n",
       "      <td>21788.898873</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>30245.0</td>\n",
       "      <td>30023.560905</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39311.0</td>\n",
       "      <td>38687.562878</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>48237.0</td>\n",
       "      <td>47082.913640</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>57004.0</td>\n",
       "      <td>55225.539170</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>65769.0</td>\n",
       "      <td>62467.119115</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11422.0</td>\n",
       "      <td>13216.814113</td>\n",
       "      <td>-1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27515.0</td>\n",
       "      <td>28722.224213</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>46163.0</td>\n",
       "      <td>45406.074262</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>65258.0</td>\n",
       "      <td>62566.357483</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>83911.0</td>\n",
       "      <td>80621.345911</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>102380.0</td>\n",
       "      <td>98116.489762</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>120787.0</td>\n",
       "      <td>115084.977324</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>19933.0</td>\n",
       "      <td>20844.690772</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>44095.0</td>\n",
       "      <td>45298.804758</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>72834.0</td>\n",
       "      <td>71611.476796</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>101163.0</td>\n",
       "      <td>98675.547930</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>129234.0</td>\n",
       "      <td>127150.689326</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>156956.0</td>\n",
       "      <td>154742.880643</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>24604.0</td>\n",
       "      <td>25730.392726</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>56734.0</td>\n",
       "      <td>55916.206635</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>90309.0</td>\n",
       "      <td>88396.198430</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>123078.0</td>\n",
       "      <td>121803.706684</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>156800.0</td>\n",
       "      <td>156953.020199</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>40735.0</td>\n",
       "      <td>38047.097584</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>84679.0</td>\n",
       "      <td>82682.351296</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>127190.0</td>\n",
       "      <td>130709.967139</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>168902.0</td>\n",
       "      <td>180109.085921</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>43064.0</td>\n",
       "      <td>40179.616783</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>86769.0</td>\n",
       "      <td>87316.652273</td>\n",
       "      <td>-0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>129678.0</td>\n",
       "      <td>138036.189953</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>41837.0</td>\n",
       "      <td>39996.117913</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>83141.0</td>\n",
       "      <td>86917.880251</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>44436.0</td>\n",
       "      <td>44410.437255</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Test      Predicted  Percentage difference\n",
       "0      607.0     523.674041                   2.36\n",
       "1     1254.0    1138.026387                   1.38\n",
       "2     1836.0    1799.070652                   0.27\n",
       "3     2434.0    2478.992060                  -0.23\n",
       "4     3048.0    3194.363303                  -0.58\n",
       "5     3663.0    3887.552493                  -0.72\n",
       "6     4278.0    4559.874610                  -0.76\n",
       "7     4892.0    5157.798995                  -0.62\n",
       "8     5506.0    5672.308827                  -0.34\n",
       "9     6120.0    6116.634925                   0.01\n",
       "10    2254.0    2296.891439                  -0.24\n",
       "11    5113.0    4991.507813                   0.28\n",
       "12    8092.0    7890.920032                   0.28\n",
       "13   10856.0   10873.129458                  -0.02\n",
       "14   13682.0   14010.825728                  -0.25\n",
       "15   16699.0   17051.229096                  -0.21\n",
       "16   19689.0   20000.107205                  -0.16\n",
       "17   22667.0   22622.668748                   0.02\n",
       "18   25645.0   24879.364967                   0.30\n",
       "19    5843.0    6342.319410                  -0.94\n",
       "20   13267.0   13782.861632                  -0.40\n",
       "21   21574.0   21788.898873                  -0.10\n",
       "22   30245.0   30023.560905                   0.07\n",
       "23   39311.0   38687.562878                   0.15\n",
       "24   48237.0   47082.913640                   0.23\n",
       "25   57004.0   55225.539170                   0.29\n",
       "26   65769.0   62467.119115                   0.47\n",
       "27   11422.0   13216.814113                  -1.54\n",
       "28   27515.0   28722.224213                  -0.42\n",
       "29   46163.0   45406.074262                   0.15\n",
       "30   65258.0   62566.357483                   0.38\n",
       "31   83911.0   80621.345911                   0.35\n",
       "32  102380.0   98116.489762                   0.37\n",
       "33  120787.0  115084.977324                   0.41\n",
       "34   19933.0   20844.690772                  -0.45\n",
       "35   44095.0   45298.804758                  -0.25\n",
       "36   72834.0   71611.476796                   0.15\n",
       "37  101163.0   98675.547930                   0.22\n",
       "38  129234.0  127150.689326                   0.14\n",
       "39  156956.0  154742.880643                   0.12\n",
       "40   24604.0   25730.392726                  -0.44\n",
       "41   56734.0   55916.206635                   0.13\n",
       "42   90309.0   88396.198430                   0.19\n",
       "43  123078.0  121803.706684                   0.09\n",
       "44  156800.0  156953.020199                  -0.01\n",
       "45   40735.0   38047.097584                   0.65\n",
       "46   84679.0   82682.351296                   0.21\n",
       "47  127190.0  130709.967139                  -0.23\n",
       "48  168902.0  180109.085921                  -0.53\n",
       "49   43064.0   40179.616783                   0.65\n",
       "50   86769.0   87316.652273                  -0.06\n",
       "51  129678.0  138036.189953                  -0.53\n",
       "52   41837.0   39996.117913                   0.42\n",
       "53   83141.0   86917.880251                  -0.39\n",
       "54   44436.0   44410.437255                   0.01"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Test\" : np.exp(Y_test), \"Predicted\" : np.exp(Y_pred), \"Percentage difference\" : np.round(100*(Y_test-Y_pred)/Y_pred, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso estimator prediction MAPE:  0.006 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Lasso estimator prediction MAPE: \",  np.round((100*(Y_test-Y_pred)/Y_pred).mean(), 3), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclussions\n",
    "\n",
    "As we have seen, the Lasso regression model has an excelent performance over other methodologies, even surpassing chainladder method as we estimated an error between 7% and 0.1\\%, versus a Lasso that gives us a consistent 0.006\\%.\n",
    "\n",
    "We can conclude that implementing Lasso regularization methods bring IBNR's regression a better consistent estimation and a better precision for predictions. This is very useful from business perspective, as a company will seek for optimize their liabilities with respect to their assets, as claims are the larger risk source for an insurer.\n",
    "\n",
    "However, the model could be revisited on the strenght of Lasso methdologies, it could be a matter of study the implementation of elastic net alternatives  to Lasso regularization. Furthermore, this tunning was realized using a very short companies sample for meet with reasonable time processing of run-off triangles data.\n",
    "\n",
    "Lastly, even when the Lasso model is the most accurate, we must observe that chainladder traditional procedure offers a practical and less time and resources consuming method that is pretty precise. So the trade-off between resources and precision has to be taken into account when selecting predictive strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "- Verrall, R. J. (1994). Statistical methods for the chain ladder technique. In Casualty Actuarial Society Forum (Vol. 1, pp. 393-446)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiEntorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
